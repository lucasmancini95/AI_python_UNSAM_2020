{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Lineales - Parte 2. Sobreajuste y Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobreajuste\n",
    "\n",
    "Discutimos la semana pasada el fenómeno del sobreajuste (*overfitting*), que ocurre cuando intentamos optimizar un modelo demasiado complejo para la cantidad de datos que tenemos.\n",
    "\n",
    "Presentamos esto con el ejemplo de la regresión polinomial a datos sinusoidales. Vamos a ver esto más en detalle acá."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, corremos la celda de preparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"06_Regularizacion\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"plots\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos ahora un conjunto de datos sintéticos, similares a los del Bishop (ver Apéndice A del libro). Además, generemos un conjunto de testeo, que vamos a usar más tarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rr\n",
    "\n",
    "ndata = 10\n",
    "ntest = 100\n",
    "# \n",
    "x = rr.rand(ndata, 1)\n",
    "xtest = rr.rand(ntest, 1)\n",
    "\n",
    "# El modelo real (ground truth)\n",
    "t = np.sin(2*np.pi * x)\n",
    "ttest = np.sin(2*np.pi * xtest)\n",
    "\n",
    "# Agregemos error normal a los datos, con desviación standard 0.3\n",
    "t += rr.randn(ndata, 1) * 0.3\n",
    "ttest += rr.randn(ntest, 1) * 0.3\n",
    "\n",
    "# Arrays para representar el modelo verdadero\n",
    "x_ = np.linspace(0, 1, 100)\n",
    "t_  = np.sin(2*np.pi * x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_truth(ax=None):\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    # Y veamos a qué se parece (hacemos una funcionn poruq esto lo vamos a usar mucho)\n",
    "    ax.plot(x_, t_, '-', color='LightGreen', lw=1)\n",
    "    ax.plot(x, t, 'o', mfc='None')\n",
    "    return\n",
    "\n",
    "plot_data_truth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentar modelar estos datos con un modelo lineal, con funciones base polinomiales de orden $M$:\n",
    "\n",
    "$$\n",
    "y(x, \\mathbf{w}) = \\sum_{j=0}^M w_j \\phi_j(x)\\;\\;,\n",
    "$$\n",
    "\n",
    "donde $\\phi_j(x) = x^j$. Probemos grados diferentes, $M$. Para simplificar la cosa, escribimos una función que genere la matriz de diseño para el grado que querramos. \n",
    "\n",
    "**¿Se animan a codearla ustedes?** Recuerden que una función práctica de <tt>numpy</tt> es <tt>hstack</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrizdise(x, M=2):\n",
    "    \"\"\"\n",
    "    Produce la matriz de diseño con features polinomiales de grado M\n",
    "    \n",
    "    :param x: vector columna con la variable input\n",
    "    :type x: np.array of shape (n, 1)\n",
    "    :param M: grado de las features polinomiales, defaults to 2.\n",
    "    :type M: int, optional\n",
    "    :return phi: matriz de diseño con features polinomiales\n",
    "    :rtype: np.array of shape (n, M+1)\n",
    "    \"\"\"  \n",
    "    phi = 0\n",
    "    \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, existe algo en <tt>ScikitLearn</tt> que hace exactamente esto. Usemoslo y comparemos los resultados. Esto es una especie de prueba para el código que acaban de escribir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pp\n",
    "\n",
    "M = 9\n",
    "polyfeat = pp.PolynomialFeatures(M)\n",
    "\n",
    "# Como simpre, todas las clases tiene el método transform\n",
    "phi = polyfeat.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifiquemos si es lo mismo\n",
    "assert np.allclose(phi, matrizdise(x, polyfeat.degree)), \"Algo está mal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada valor de M, vamos a querer calcular el RMSE en el conjuto de entrenamiento. Recuerden:\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(y(x_i, \\mathbf{w_\\mathrm{ML}}) - t_i\\right)^2}\\;\\;.\n",
    "$$\n",
    "Vamos, entonces a escribir una función que implemente este error, dado el vector de predicciónes, $y(x_i, \\mathbf{w}_\\mathrm{ML})$ y los datos de entrenamiento $t_i$, con $i = {0, 1, ... , n}$.\n",
    "\n",
    "Otra vez, les pido que lo hagan ustedes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(t, y):\n",
    "    \"\"\"\n",
    "    Produce la matriz de diseño con features polinomiales de grado M\n",
    "    \n",
    "    :param t: vector columna con los datos salida del conjunto de entrenamiento.\n",
    "    :type t: np.array of shape (n, 1)\n",
    "    :param y: vector columna con las predicciones del modelo.\n",
    "    :type y: np.array of shape (n, 1)\n",
    "    :return rmse: raíz del error medio cuadrático\n",
    "    :rtype: float\n",
    "    \"\"\"  \n",
    "    rmse = np.sqrt( np.sum((t - y)**2) / len(t) )\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y una vez más, parece que <tt>ScikitLearn</tt> se nos adelantó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, escribamos una claes (ojo ahí) que haga regresión de modelos lineales: que calcule los estimadores de máxima verosimilitud de los parámetros y que haga predicciones. Esto ya no es tan fácil, y nunca lo hicimos, pero es la puerta de ingreso a un mundo mejor: el mundo de la programación orientada a objetos. Acá va."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionLineal(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parametros = None\n",
    "        self.prediccion = None\n",
    "    \n",
    "    def fit(self, Phi, t):\n",
    "        \"\"\"\n",
    "        Ajusta el modelo lineal.\n",
    "\n",
    "        :param Phi: matriz de diseño\n",
    "        :type Phi: array-like de shape (n_muestras, n_features)\n",
    "        :param t: valores verdaderos.\n",
    "        :type t: array-like de shape (n_muestras, 1)\n",
    "\n",
    "        :returns: self, una versión de sí mismo.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Escribir la solución de las ecuaciones normales. De hecho, ya lo hicimos la semana pasada.\n",
    "        # Acá está el código\n",
    "        \n",
    "        # Ahora calculemos el producto de phi por su transpuesta y verifiquemos que la forma es la correcta\n",
    "        pp = np.dot(Phi.T, Phi)\n",
    "\n",
    "        # y el producto entre phi y el vector t\n",
    "        yy = np.dot(Phi.T, t)\n",
    "        \n",
    "        wml = np.linalg.solve(pp, yy)\n",
    "        \n",
    "        # Asegurarse de que el resultado queda guardado en la variable\n",
    "        self.parametros = wml\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def predict(self, Phi_pred):\n",
    "        \"\"\"\n",
    "        Realiza predicciones para el arreglo de input x\n",
    "\n",
    "        :param Phi_pred: Matriz de diseño calculada en los puntos en los que se quiere obtener una predicción.\n",
    "        :type Phi_pred: array-like de shape (n_muestras, n_features)\n",
    "\n",
    "        :returns t_pred: predicción para el arreglo de entrada (n_muestras, 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        # En nuestro caso, n_variables = 1, pero está bueno escribir la función lo más general posible.\n",
    "        # Esto también lo hicimos la semana pasada\n",
    "        \n",
    "        if self.parametros is None:\n",
    "            raise AttributeError(\"Todavía no se ajustó ningún modelo\")\n",
    "        \n",
    "        t_pred = Phi_pred @ self.parametros\n",
    "\n",
    "        self.prediccion = t_pred\n",
    "        \n",
    "        return t_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polyfeat = pp.PolynomialFeatures(3)\n",
    "mirl = RegresionLineal()\n",
    "\n",
    "phi = polyfeat.fit_transform(x)\n",
    "mirl.fit(phi, t)\n",
    "#print(mirl.parametros)\n",
    "#print(mirl.predict(phi))\n",
    "\n",
    "phi_ = polyfeat.fit_transform(x_[:, np.newaxis])\n",
    "#print(phi_.shape)\n",
    "ypred_ = mirl.predict(phi_)\n",
    "\n",
    "plot_data_truth()\n",
    "plt.plot(x_, ypred_, '.r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A esta altura no sorprende que <tt>sklearn</tt> tenga algo muy similar. Veamos la documentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer la regresión polinomial, vemos que entonces primero hay que calcular la matriz de diseño usando los features polinomiales y después resolver las ecuaciones normales. Por suerte, <tt>sklearn</tt> tiene una clase que permite hacer ambos pasos a la vez: se llama <tt>Pipeline</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "polyregression = Pipeline([('features', pp.PolynomialFeatures(degree=7)),\n",
    "                          ('regression', LinearRegression())\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora se puede hacer todo con un simple llamada a <tt>fit</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordemos que x y t son los datos\n",
    "plot_data_truth()\n",
    "\n",
    "# Ajustemos el modelo a ellos\n",
    "polyregression.fit(x, t)\n",
    "\n",
    "# Y calculemos la predicción en un array bien muestreado y en los x de training\n",
    "y = polyregression.predict(x)\n",
    "y_ = polyregression.predict(x_[:, np.newaxis])\n",
    "\n",
    "# ahora hagamos un plot\n",
    "plt.plot(x_, y_, '-r')\n",
    "plt.ylim(-2.5, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos la función que escribimos para calcular el RMSE, y veamos el valor de los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(polyreg, truth, prediction):\n",
    "    rmse = mean_squared_error(prediction, truth, squared=False)\n",
    "    \n",
    "    print('Error RMSE para un polinomio de grado {}'\n",
    "          ': {:.3f}'.format(polyreg.named_steps['features'].degree, rmse))\n",
    "    \n",
    "    print('Los parámetros son {}'.format(polyreg.named_steps['regression'].coef_))\n",
    "    \n",
    "    return rmse, polyreg.named_steps['regression'].coef_\n",
    "\n",
    "A = print_results(polyregression, y, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, pongamos todo esto junto y armemos una función que ajuste los datos con polinomios de distintos órdenes, y devuelva el error y los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data(grados=[0, 1, 3, 5], plot=True):\n",
    "    \n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(int(np.ceil(len(grados)/3)), 3)\n",
    "    \n",
    "    errors = np.zeros(len(grados))\n",
    "    errorstest = np.zeros(len(grados))\n",
    "    \n",
    "    for i, grado in enumerate(grados):\n",
    "        # Crea un pipeline de sklearn con features de grado \"grado\"\n",
    "        modelo = Pipeline([('features', pp.PolynomialFeatures(degree=grado)),\n",
    "                           ('regression', LinearRegression())\n",
    "                          ])\n",
    "        \n",
    "        # Ajusta el modelo a los datos\n",
    "        modelo = modelo.fit(x, t)\n",
    "        \n",
    "        # Calcula la predicción en el conjunto de entrenamiento\n",
    "        y = modelo.predict(x)\n",
    "        \n",
    "        # Calcula la predicción en el conjunto de test\n",
    "        ytest = modelo.predict(xtest)\n",
    "        \n",
    "        # Print y calcula errores\n",
    "        errors[i] = print_results(modelo, t, y)[0]\n",
    "        errorstest[i] = mean_squared_error(ytest, ttest, squared=False)\n",
    "        \n",
    "        if plot:\n",
    "            # Si vamos a hacer un plot, también para el array bien sampleado\n",
    "            y_ = modelo.predict(x_[:, np.newaxis])\n",
    "                                \n",
    "            # Elige el eje adecuado            \n",
    "            ax = axs[np.unravel_index(i, axs.shape)]\n",
    "            \n",
    "            # First plot data and truth\n",
    "            plot_data_truth(ax)\n",
    "            \n",
    "            # Add prediction\n",
    "            ax.plot(x_, y_, 'r-')\n",
    "            ax.set_ylim(-2.5, 2.5)\n",
    "            \n",
    "            ax.set_title('Grado {}'.format(grado))\n",
    "                \n",
    "    return grados, errors, errorstest\n",
    "\n",
    "grados, errors, errorst = fit_data(grados=[0, 1, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos ahora un gráfico parecido al de Bishop, que muestra el problema del overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grados, errors, '-o', label='Training')\n",
    "plt.semilogy(grados, errorst, '-o', label='Test', color='r')\n",
    "\n",
    "plt.xlabel('Grado del polinimio (M)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Hasta acá revisitamos el concepto de sobreajuste y lo vimos en acción en un caso bien particular. Datos sinusoidales con una regresión polinomial. \n",
    "\n",
    "Vimos el uso de varias clases del paquete <tt>sklearn</tt>, en particular las que permiten hacer features polinomiales ([PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)), la que permite hacer regresión con modelos lineales, ([LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)), y la que permite automatizar varias acciones en un solo comando.\n",
    "([Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)). Puse los links a la documentación de <tt>sklearn</tt>\n",
    "\n",
    "En la guía de ejercicios se les pide que experimenten cambiando el número de puntos en el conjunto de entrenamiento, para que vean cómo cambia la severidad del sobreajuste con este parámetro.\n",
    "\n",
    "Vemos que para detectar el sobreajuste, se necesita recurrir, en general, al conjunto de test. Esto es problemático, porque si se detecta *overfitting*, entonces ese conjunto ya no puede funcionar como conjunto de test, y necesitamos datos nuevos. Para resolver esto, se puede recurrir a la técnica de validación cruzada, que es lo que vamos a ver ahora.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada\n",
    "\n",
    "La semana pasada escribimos una función para separar aleatoriamente los datos en conjunto de test y de entrenamiento. El mismo procedimiento se podría emplear en el conjunto de entrenamiento para identificar conjuntos de validación. \n",
    "\n",
    "En realidad, existe un gran número de maneras para elegir el conjunto de validación y/o hacer validación cruzada. Una vez más, la [documentación de sklearn](https://scikit-learn.org/stable/modules/cross_validation.html) sobre este tema es un excelente punto de partida para enterarse de más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma más sencilla para usar Cross Validation con sklearn es <tt>cross_val_score</tt>, que permite hacer K-folding fácilmente. Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "modelo = Pipeline([('features', pp.PolynomialFeatures(degree=5)),\n",
    "                    ('regression', LinearRegression())\n",
    "                    ])\n",
    "\n",
    "# Leave one out\n",
    "scores = cross_val_score(modelo, x, t, cv=10, scoring='neg_root_mean_squared_error')\n",
    "errores = -scores\n",
    "print(errores, errores.mean(), errores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora puedo hacer una función parecida a la anterior, pero que calcule los scores con crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "\n",
    "def cv_multimodel(grados=range(10), cv=len(x), plot=True):\n",
    "        \n",
    "    rsmes = np.zeros(len(grados))\n",
    "    std_rsmes = np.zeros(len(grados))\n",
    "    \n",
    "    for i, grado in enumerate(grados):\n",
    "        # Crea un pipeline de sklearn con features de grado \"grado\"\n",
    "        modelo = Pipeline([('features', pp.PolynomialFeatures(degree=grado)),\n",
    "                           ('regression', LinearRegression())\n",
    "                          ])\n",
    "        \n",
    "        # Hace K-folding\n",
    "        scores = cross_val_score(modelo, x, t, cv=cv, scoring='neg_root_mean_squared_error')\n",
    "            \n",
    "        # Como se usa un score, hay que pasarlo a Error cambiando de signo.\n",
    "        rsmes[i] = (-scores).mean()\n",
    "        std_rsmes[i] = (-scores).std()\n",
    "        \n",
    "    if plot:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        # Sin errores\n",
    "        ax.semilogy(grados, rsmes, 'o-', mfc='None')\n",
    "        \n",
    "        # Con errores\n",
    "#         ax.errorbar(grados, rsmes, std_rsmes, fmt='-o')\n",
    "#         ax.set_yscale('log')\n",
    "        \n",
    "        ax.set_xlabel('Grado')\n",
    "        ax.set_ylabel('mean RMSE')\n",
    "                \n",
    "    return grados, rsmes, std_rsmes\n",
    "\n",
    "grados, errors, errorst = cv_multimodel()\n",
    "\n",
    "# loo = LeaveOneOut()\n",
    "# loo.get_n_splits(x)\n",
    "# scores = []\n",
    "# for train_index, test_index in loo.split(x):\n",
    "#     modelo = modelo.fit(x[train_index], t[train_index])\n",
    "#     y = modelo.predict(x[test_index])\n",
    "#     scores.append(mean_squared_error(t[test_index], y, squared=True))\n",
    "    \n",
    "# scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el mejor modelo, elegido a partir de CV\n",
    "modelo = Pipeline([('features', pp.PolynomialFeatures(degree=3)),\n",
    "                    ('regression', LinearRegression())\n",
    "                    ])\n",
    "# Ajustar con mi conjunto de training.\n",
    "modelo.fit(x, t)\n",
    "\n",
    "# Evaluar en el conjunto de test.\n",
    "ytest = modelo.predict(xtest)\n",
    "print('El error del mejor modelo en el conjunto de test es {:.2e}.'.format(mean_squared_error(ttest, ytest)))\n",
    "\n",
    "# Leave one out\n",
    "# scores = cross_val_score(modelo, x, t, cv=10, scoring='neg_root_mean_squared_error')\n",
    "# errores = -scores\n",
    "# print(errores, errores.mean(), errores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización\n",
    "\n",
    "Veamos cómo funciona la regularización usando <tt>Ridge</tt> y <tt>Lasso</tt>. Ambas clases están definidas por con un hiperparámetro, $\\alpha$, que equivale al coeficiente $\\lambda$ que acabamos de ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "modelo = Pipeline([('features', pp.PolynomialFeatures(degree=9)),\n",
    "                         ('regression', LinearRegression())\n",
    "                          ])\n",
    "\n",
    "modelo_ridge = Pipeline([('features', pp.PolynomialFeatures(degree=9)),\n",
    "                         ('regression', Ridge(alpha=1e-4))\n",
    "                          ])\n",
    "\n",
    "modelo_lasso = Pipeline([('features', pp.PolynomialFeatures(degree=9)),\n",
    "                         ('regression', Lasso(alpha=1e-4, tol=1e-3, max_iter=20000))\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = modelo.fit(x, t)\n",
    "modelo_ridge = modelo_ridge.fit(x, t)\n",
    "modelo_lasso = modelo_lasso.fit(x, t)\n",
    "\n",
    "print('No regularizado')\n",
    "print(modelo.named_steps['regression'].coef_)\n",
    "print('#######')\n",
    "print('Ridge')\n",
    "print(modelo_ridge.named_steps['regression'].coef_)\n",
    "print('#######')\n",
    "print('LASSO')\n",
    "print(modelo_lasso.named_steps['regression'].coef_)\n",
    "\n",
    "y_ = modelo.predict(x_[:, np.newaxis])\n",
    "yridge_ = modelo_ridge.predict(x_[:, np.newaxis])\n",
    "ylasso_ = modelo_lasso.predict(x_[:, np.newaxis])\n",
    "\n",
    "plot_data_truth()\n",
    "plt.plot(x_, y_, '-m', label='no regularizado')\n",
    "plt.plot(x_, yridge_, '-r', label='Ridge')\n",
    "plt.plot(x_, ylasso_, '-b', label='Lasso')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.ylim(-1.5, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo cambia el error en el conjuno de test con el parámetro alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino alphas\n",
    "alphas = np.logspace(-20, -5, 25, base=np.e)\n",
    "\n",
    "# Inicializo arreglo\n",
    "#rmse_train = np.zeros_like(alphas) \n",
    "rmse_test = np.zeros_like(alphas)\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "   \n",
    "    modelo_ridge = Pipeline([('features', pp.PolynomialFeatures(degree=9)),\n",
    "                             ('regression', Ridge(alpha=alpha))\n",
    "                              ])\n",
    "    # Ajusta el modelo\n",
    "    modelo_ridge = modelo_ridge.fit(x, t)\n",
    "    \n",
    "    # Calcula la predicción en el conjunto de test y de train\n",
    "    #ytrain = modelo_ridge.predict(x)\n",
    "    ytest = modelo_ridge.predict(xtest)\n",
    "    \n",
    "    # Calcula el error\n",
    "    #rmse_train[i] = mean_squared_error(t, ytrain, squared=False)\n",
    "    rmse_test[i] = mean_squared_error(ttest, ytest, squared=False)\n",
    "    \n",
    "# Ahora ploteo el resultado.\n",
    "plt.semilogx(alphas, rmse_test, 'o-', label='Test')\n",
    "#plt.loglog(alphas, rmse_train, 'o-', label='Train')\n",
    "plt.xlabel('Parámetro de regularización')\n",
    "plt.ylabel('Mean RMSE over splits')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "print('El mejor valor de alpha es {:.2e}'.format(alphas[np.argmin(rmse_test)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto está muy bien, pero ahora el problema de la complejidad parece haberse trasladado a la elección del parámetro de regularización, $\\alpha$. Acá de nuevo recurrimos a el conjunto de test para justar un (hiper)parámetro.\n",
    "\n",
    "En lugar de eso, podemos usar de nuevo Cross-Validation. Existen algunas clases de <tt>sklearn</tt> muy poderosas que hacen todo eso junto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# Compute polinomial features\n",
    "polyfeat = pp.PolynomialFeatures(degree=9)\n",
    "phi = polyfeat.fit_transform(x)\n",
    "\n",
    "# Regresión con Ridge haciendo CV en el hiperparámetro alpha\n",
    "# Usamos cv=len(x) para hacer LOO-CV\n",
    "ridgecv = RidgeCV(alphas=alphas, cv=len(x), scoring='neg_root_mean_squared_error')\n",
    "ridgecv = ridgecv.fit(phi, t)\n",
    "\n",
    "# Print\n",
    "print('El mejor valor para el coeficiente de regularización es {:.2e}'.format(ridgecv.alpha_))\n",
    "\n",
    "# Veamos el ajust\n",
    "phi_ = polyfeat.fit_transform(x_[:, np.newaxis])\n",
    "yridgecv_ = ridgecv.predict(phi_)\n",
    "\n",
    "plot_data_truth()\n",
    "plt.plot(x_, yridgecv_, label='Ridge')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "print('Ridge')\n",
    "print(ridgecv.coef_)\n",
    "\n",
    "phitest = polyfeat.fit_transform(xtest)\n",
    "ytest = ridgecv.predict(phitest)\n",
    "\n",
    "\n",
    "print('El error del mejor modelo en el conjunto de test es {:.2e}.'.format(mean_squared_error(ttest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
